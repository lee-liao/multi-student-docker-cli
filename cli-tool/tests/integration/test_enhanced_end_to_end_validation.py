#!/usr/bin/env python3
"""
Enhanced End-to-End Workflow Validation
Comprehensive testing for complete student workflows with enhanced database
initialization testing and improved network isolation validation.
"""

import sys
import os
import tempfile
import shutil
import subprocess
import time
import json
import socket
import threading
from typing import Dict, List, Any, Optional
from pathlib import Path

# Add the cli-tool directory to the path
sys.path.append(os.path.join(os.path.dirname(os.path.abspath(__file__)), '..', '..'))

def safe_print(message):
    """Print message with safe encoding for Windows"""
    try:
        print(message)
    except UnicodeEncodeError:
        safe_message = message.replace('âœ…', '[PASS]').replace('âŒ', '[FAIL]').replace('âš ï¸', '[WARN]')
        safe_message = safe_message.replace('ðŸš€', '[START]').replace('ðŸŽ¯', '[TARGET]').replace('ðŸ“Š', '[STATS]')
        safe_message = safe_message.replace('âœ“', 'OK').replace('ðŸ’¡', 'TIP').replace('ðŸ“‹', 'INFO')
        safe_message = safe_message.replace('ðŸ³', '[DOCKER]').replace('ðŸ”—', '[NETWORK]').replace('ðŸ—„ï¸', '[DATABASE]')
        print(safe_message)

class EnhancedEndToEndValidator:
    """Enhanced end-to-end workflow validator with comprehensive testing"""
    
    def __init__(self):
        self.docker_available = self._check_docker_availability()
        self.compose_available = self._check_compose_availability()
        self.temp_dir = None
        self.test_projects = []
        self.running_containers = []
        self.test_users = ["student001", "student002", "student003"]
        self.base_port = 8000
        
    def _check_docker_availability(self) -> bool:
        """Check if Docker is available"""
        try:
            result = subprocess.run(['docker', 'version'], capture_output=True, timeout=10)
            return result.returncode == 0
        except (subprocess.TimeoutExpired, FileNotFoundError):
            return False
    
    def _check_compose_availability(self) -> bool:
        """Check if Docker Compose is available"""
        try:
            result = subprocess.run(['docker-compose', 'version'], capture_output=True, timeout=10)
            if result.returncode == 0:
                return True
            result = subprocess.run(['docker', 'compose', 'version'], capture_output=True, timeout=10)
            return result.returncode == 0
        except (subprocess.TimeoutExpired, FileNotFoundError):
            return False
    
    def setup_multi_user_environment(self):
        """Set up multi-user test environment"""
        self.temp_dir = tempfile.mkdtemp()
        safe_print(f"[INFO] Multi-user test environment: {self.temp_dir}")
        
        # Create directory structure for multiple users
        self.projects_base = os.path.join(self.temp_dir, "dockeredServices")
        self.templates_dir = os.path.join(self.temp_dir, "templates")
        
        os.makedirs(self.projects_base)
        os.makedirs(self.templates_dir)
        
        # Create enhanced templates with database support
        self._create_enhanced_templates()
        
        # Create user-specific directories
        for user in self.test_users:
            user_dir = os.path.join(self.projects_base, user)
            os.makedirs(user_dir, exist_ok=True)
        
        return True
    
    def _create_enhanced_templates(self):
        """Create enhanced templates with comprehensive database support"""
        
        # Enhanced Common Template with PostgreSQL and MongoDB
        common_template = """
version: '3.8'
services:
  postgres:
    image: postgres:13-alpine
    environment:
      POSTGRES_DB: {{DB_NAME}}
      POSTGRES_USER: {{DB_USER}}
      POSTGRES_PASSWORD: {{DB_PASSWORD}}
    ports:
      - "{{POSTGRES_PORT}}:5432"
    volumes:
      - postgres_data:/var/lib/postgresql/data
      - ./init-scripts/postgres:/docker-entrypoint-initdb.d
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U {{DB_USER}} -d {{DB_NAME}}"]
      interval: 10s
      timeout: 5s
      retries: 5
    networks:
      - {{USERNAME}}_network

  mongodb:
    image: mongo:5.0
    environment:
      MONGO_INITDB_ROOT_USERNAME: {{MONGO_USER}}
      MONGO_INITDB_ROOT_PASSWORD: {{MONGO_PASSWORD}}
      MONGO_INITDB_DATABASE: {{MONGO_DB}}
    ports:
      - "{{MONGO_PORT}}:27017"
    volumes:
      - mongo_data:/data/db
      - ./init-scripts/mongo:/docker-entrypoint-initdb.d
    healthcheck:
      test: ["CMD", "mongo", "--eval", "db.adminCommand('ping')"]
      interval: 10s
      timeout: 5s
      retries: 5
    networks:
      - {{USERNAME}}_network

  redis:
    image: redis:6-alpine
    ports:
      - "{{REDIS_PORT}}:6379"
    volumes:
      - redis_data:/data
    command: redis-server --appendonly yes
    healthcheck:
      test: ["CMD", "redis-cli", "ping"]
      interval: 10s
      timeout: 5s
      retries: 3
    networks:
      - {{USERNAME}}_network

volumes:
  postgres_data:
  mongo_data:
  redis_data:

networks:
  {{USERNAME}}_network:
    driver: bridge
    name: {{USERNAME}}_network
"""
        
        # Enhanced RAG Template
        rag_template = """
version: '3.8'
services:
  rag_app:
    image: python:3.9-slim
    ports:
      - "{{RAG_APP_PORT}}:8000"
    environment:
      - PYTHONPATH=/app
      - DATABASE_URL=postgresql://{{DB_USER}}:{{DB_PASSWORD}}@postgres:5432/{{DB_NAME}}
      - MONGO_URL=mongodb://{{MONGO_USER}}:{{MONGO_PASSWORD}}@mongodb:27017/{{MONGO_DB}}
      - REDIS_URL=redis://redis:6379
      - USER_ID={{USERNAME}}
      - PROJECT_NAME={{PROJECT_NAME}}
    working_dir: /app
    command: ["python", "-c", "import time; print('RAG App Started'); time.sleep(300)"]
    depends_on:
      postgres:
        condition: service_healthy
      mongodb:
        condition: service_healthy
      redis:
        condition: service_healthy
    networks:
      - {{USERNAME}}_network
    volumes:
      - ./app:/app

  vector_db:
    image: pgvector/pgvector:pg15
    environment:
      POSTGRES_DB: {{VECTOR_DB_NAME}}
      POSTGRES_USER: {{DB_USER}}
      POSTGRES_PASSWORD: {{DB_PASSWORD}}
    ports:
      - "{{VECTOR_PORT}}:5432"
    volumes:
      - vector_data:/var/lib/postgresql/data
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U {{DB_USER}} -d {{VECTOR_DB_NAME}}"]
      interval: 10s
      timeout: 5s
      retries: 5
    networks:
      - {{USERNAME}}_network

volumes:
  vector_data:

networks:
  {{USERNAME}}_network:
    external: true
    name: {{USERNAME}}_network
"""
        
        # Enhanced Agent Template
        agent_template = """
version: '3.8'
services:
  agent:
    image: python:3.9-slim
    ports:
      - "{{AGENT_PORT}}:8000"
    environment:
      - PYTHONPATH=/app
      - DATABASE_URL=postgresql://{{DB_USER}}:{{DB_PASSWORD}}@postgres:5432/{{DB_NAME}}
      - MONGO_URL=mongodb://{{MONGO_USER}}:{{MONGO_PASSWORD}}@mongodb:27017/{{MONGO_DB}}
      - REDIS_URL=redis://redis:6379
      - USER_ID={{USERNAME}}
      - PROJECT_NAME={{PROJECT_NAME}}
    working_dir: /app
    command: ["python", "-c", "import time; print('Agent Started'); time.sleep(300)"]
    depends_on:
      postgres:
        condition: service_healthy
      mongodb:
        condition: service_healthy
      redis:
        condition: service_healthy
    networks:
      - {{USERNAME}}_network
    volumes:
      - ./agent:/app

  task_queue:
    image: redis:6-alpine
    ports:
      - "{{TASK_QUEUE_PORT}}:6379"
    volumes:
      - task_queue_data:/data
    command: redis-server --appendonly yes
    networks:
      - {{USERNAME}}_network

volumes:
  task_queue_data:

networks:
  {{USERNAME}}_network:
    external: true
    name: {{USERNAME}}_network
"""
        
        # Create template directories and files
        templates = {
            "common": common_template,
            "rag": rag_template,
            "agent": agent_template
        }
        
        for template_name, template_content in templates.items():
            template_dir = os.path.join(self.templates_dir, template_name)
            os.makedirs(template_dir)
            
            template_file = os.path.join(template_dir, "docker-compose.yml.template")
            with open(template_file, 'w') as f:
                f.write(template_content)
            
            # Create init scripts directory
            init_scripts_dir = os.path.join(template_dir, "init-scripts")
            os.makedirs(init_scripts_dir)
            os.makedirs(os.path.join(init_scripts_dir, "postgres"))
            os.makedirs(os.path.join(init_scripts_dir, "mongo"))
            
            # Create PostgreSQL init script
            postgres_init = """
-- Initialize database for {{PROJECT_NAME}}
CREATE SCHEMA IF NOT EXISTS {{USERNAME}}_schema;
CREATE TABLE IF NOT EXISTS {{USERNAME}}_schema.projects (
    id SERIAL PRIMARY KEY,
    name VARCHAR(255) NOT NULL,
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
);
INSERT INTO {{USERNAME}}_schema.projects (name) VALUES ('{{PROJECT_NAME}}');
"""
            
            with open(os.path.join(init_scripts_dir, "postgres", "01-init.sql"), 'w') as f:
                f.write(postgres_init)
            
            # Create MongoDB init script
            mongo_init = """
// Initialize MongoDB for {{PROJECT_NAME}}
db = db.getSiblingDB('{{MONGO_DB}}');
db.createCollection('{{USERNAME}}_projects');
db.{{USERNAME}}_projects.insertOne({
    name: '{{PROJECT_NAME}}',
    user: '{{USERNAME}}',
    created_at: new Date()
});
"""
            
            with open(os.path.join(init_scripts_dir, "mongo", "01-init.js"), 'w') as f:
                f.write(mongo_init)
    
    def test_complete_multi_user_workflows(self) -> bool:
        """Test complete workflows for multiple users simultaneously"""
        safe_print("\n[START] Multi-User Workflow Validation")
        safe_print("="*60)
        
        try:
            from src.core.project_manager import ProjectManager
            from src.core.port_assignment import PortAssignment
            
            results = {"users_tested": 0, "users_passed": 0, "workflows_completed": 0}
            
            # Test each user's complete workflow
            for i, user in enumerate(self.test_users):
                safe_print(f"\n[USER] Testing workflow for {user}")
                safe_print("-"*40)
                
                try:
                    # Create port assignment for user
                    start_port = self.base_port + (i * 100)
                    end_port = start_port + 99
                    port_assignment = PortAssignment(user, start_port, end_port)
                    
                    # Initialize project manager
                    user_projects_dir = os.path.join(self.projects_base, user)
                    manager = ProjectManager(
                        base_dir=user_projects_dir,
                        templates_dir=self.templates_dir
                    )
                    
                    # Workflow Step 1: Create common infrastructure
                    safe_print(f"  [STEP] 1. Creating common infrastructure for {user}")
                    common_config = manager.create_project(
                        project_name="common",
                        template_type="common",
                        username=user,
                        port_assignment=port_assignment,
                        has_common_project=False
                    )
                    
                    self.test_projects.append((user, "common"))
                    safe_print(f"  [PASS] Common infrastructure created")
                    
                    # Workflow Step 2: Create RAG project (shared mode)
                    safe_print(f"  [STEP] 2. Creating RAG project for {user}")
                    rag_config = manager.create_project(
                        project_name=f"{user}_rag_project",
                        template_type="rag",
                        username=user,
                        port_assignment=port_assignment,
                        has_common_project=True
                    )
                    
                    self.test_projects.append((user, f"{user}_rag_project"))
                    safe_print(f"  [PASS] RAG project created")
                    
                    # Workflow Step 3: Create Agent project (standalone)
                    safe_print(f"  [STEP] 3. Creating Agent project for {user}")
                    agent_config = manager.create_project(
                        project_name=f"{user}_agent_project",
                        template_type="agent",
                        username=user,
                        port_assignment=port_assignment,
                        has_common_project=True
                    )
                    
                    self.test_projects.append((user, f"{user}_agent_project"))
                    safe_print(f"  [PASS] Agent project created")
                    
                    # Workflow Step 4: Copy project
                    safe_print(f"  [STEP] 4. Copying project for {user}")
                    copy_config = manager.copy_project(
                        source_project=f"{user}_rag_project",
                        destination_project=f"{user}_rag_copy",
                        username=user,
                        port_assignment=port_assignment
                    )
                    
                    self.test_projects.append((user, f"{user}_rag_copy"))
                    safe_print(f"  [PASS] Project copied successfully")
                    
                    results["users_tested"] += 1
                    results["users_passed"] += 1
                    results["workflows_completed"] += 4  # 4 steps per user
                    
                    safe_print(f"  [SUCCESS] Complete workflow for {user} successful")
                    
                except Exception as e:
                    results["users_tested"] += 1
                    safe_print(f"  [FAIL] Workflow for {user} failed: {str(e)}")
            
            # Verify cross-user isolation
            safe_print(f"\n[TEST] Cross-User Isolation Verification")
            if self._verify_cross_user_isolation():
                safe_print(f"  [PASS] Cross-user isolation verified")
            else:
                safe_print(f"  [WARN] Cross-user isolation issues detected")
            
            success_rate = (results["users_passed"] / results["users_tested"] * 100) if results["users_tested"] > 0 else 0
            
            safe_print(f"\n[STATS] Multi-User Workflow Results:")
            safe_print(f"  Users Tested: {results['users_tested']}")
            safe_print(f"  Users Passed: {results['users_passed']}")
            safe_print(f"  Workflows Completed: {results['workflows_completed']}")
            safe_print(f"  Success Rate: {success_rate:.1f}%")
            
            return success_rate >= 90
            
        except Exception as e:
            safe_print(f"[FAIL] Multi-user workflow test failed: {str(e)}")
            return False
    
    def _verify_cross_user_isolation(self) -> bool:
        """Verify that users are properly isolated from each other"""
        try:
            # Check that each user has their own directory structure
            for user in self.test_users:
                user_dir = os.path.join(self.projects_base, user)
                if not os.path.exists(user_dir):
                    safe_print(f"  [FAIL] User directory missing for {user}")
                    return False
                
                # Check that user projects don't interfere with each other
                user_projects = os.listdir(user_dir)
                for other_user in self.test_users:
                    if other_user != user:
                        # Ensure no cross-contamination in project names
                        for project in user_projects:
                            if other_user in project and not user in project:
                                safe_print(f"  [FAIL] Cross-user contamination detected")
                                return False
            
            # Verify port isolation
            port_ranges = {}
            for i, user in enumerate(self.test_users):
                start_port = self.base_port + (i * 100)
                end_port = start_port + 99
                port_ranges[user] = (start_port, end_port)
            
            # Check for port range overlaps
            users = list(port_ranges.keys())
            for i in range(len(users)):
                for j in range(i + 1, len(users)):
                    user1, user2 = users[i], users[j]
                    range1 = port_ranges[user1]
                    range2 = port_ranges[user2]
                    
                    # Check for overlap
                    if not (range1[1] < range2[0] or range2[1] < range1[0]):
                        safe_print(f"  [FAIL] Port range overlap between {user1} and {user2}")
                        return False
            
            return True
            
        except Exception as e:
            safe_print(f"  [ERROR] Cross-user isolation check failed: {str(e)}")
            return False
    
    def test_comprehensive_database_initialization(self) -> bool:
        """Test comprehensive database initialization for PostgreSQL and MongoDB"""
        safe_print("\n[DATABASE] Comprehensive Database Initialization Test")
        safe_print("="*60)
        
        if not self.docker_available or not self.compose_available:
            safe_print("[WARN] Docker not available - skipping database tests")
            return True
        
        results = {"databases_tested": 0, "databases_passed": 0, "init_scripts_tested": 0, "init_scripts_passed": 0}
        
        try:
            # Test PostgreSQL initialization
            safe_print("\n[DATABASE] Testing PostgreSQL Initialization")
            if self._test_postgresql_comprehensive():
                results["databases_passed"] += 1
                safe_print("  [PASS] PostgreSQL initialization successful")
            else:
                safe_print("  [FAIL] PostgreSQL initialization failed")
            results["databases_tested"] += 1
            
            # Test MongoDB initialization
            safe_print("\n[DATABASE] Testing MongoDB Initialization")
            if self._test_mongodb_comprehensive():
                results["databases_passed"] += 1
                safe_print("  [PASS] MongoDB initialization successful")
            else:
                safe_print("  [FAIL] MongoDB initialization failed")
            results["databases_tested"] += 1
            
            # Test database initialization scripts
            safe_print("\n[DATABASE] Testing Database Initialization Scripts")
            if self._test_database_init_scripts():
                results["init_scripts_passed"] += 1
                safe_print("  [PASS] Database init scripts working")
            else:
                safe_print("  [FAIL] Database init scripts failed")
            results["init_scripts_tested"] += 1
            
            # Test cross-database connectivity
            safe_print("\n[DATABASE] Testing Cross-Database Connectivity")
            if self._test_cross_database_connectivity():
                safe_print("  [PASS] Cross-database connectivity working")
            else:
                safe_print("  [WARN] Cross-database connectivity issues")
            
            success_rate = ((results["databases_passed"] + results["init_scripts_passed"]) / 
                           (results["databases_tested"] + results["init_scripts_tested"]) * 100) if (results["databases_tested"] + results["init_scripts_tested"]) > 0 else 0
            
            safe_print(f"\n[STATS] Database Test Results:")
            safe_print(f"  Databases Tested: {results['databases_tested']}")
            safe_print(f"  Databases Passed: {results['databases_passed']}")
            safe_print(f"  Init Scripts Tested: {results['init_scripts_tested']}")
            safe_print(f"  Init Scripts Passed: {results['init_scripts_passed']}")
            safe_print(f"  Success Rate: {success_rate:.1f}%")
            
            return success_rate >= 75
            
        except Exception as e:
            safe_print(f"[FAIL] Database initialization test failed: {str(e)}")
            return False
    
    def _test_postgresql_comprehensive(self) -> bool:
        """Comprehensive PostgreSQL testing"""
        try:
            # Create a test project with PostgreSQL
            test_project_dir = os.path.join(self.temp_dir, "postgres_test")
            os.makedirs(test_project_dir)
            
            # Create docker-compose for PostgreSQL test
            compose_content = """
version: '3.8'
services:
  postgres:
    image: postgres:13-alpine
    environment:
      POSTGRES_DB: testdb
      POSTGRES_USER: testuser
      POSTGRES_PASSWORD: testpass
    ports:
      - "5432:5432"
    volumes:
      - postgres_data:/var/lib/postgresql/data
      - ./init-scripts:/docker-entrypoint-initdb.d
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U testuser -d testdb"]
      interval: 10s
      timeout: 5s
      retries: 5

volumes:
  postgres_data:
"""
            
            with open(os.path.join(test_project_dir, "docker-compose.yml"), 'w') as f:
                f.write(compose_content)
            
            # Create init scripts directory and script
            init_dir = os.path.join(test_project_dir, "init-scripts")
            os.makedirs(init_dir)
            
            init_script = """
-- Test initialization script
CREATE SCHEMA IF NOT EXISTS test_schema;
CREATE TABLE IF NOT EXISTS test_schema.test_table (
    id SERIAL PRIMARY KEY,
    name VARCHAR(255) NOT NULL,
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
);
INSERT INTO test_schema.test_table (name) VALUES ('test_entry');
"""
            
            with open(os.path.join(init_dir, "01-init.sql"), 'w') as f:
                f.write(init_script)
            
            # Start PostgreSQL container
            safe_print("    [DOCKER] Starting PostgreSQL container...")
            result = subprocess.run(
                ['docker-compose', 'up', '-d'],
                cwd=test_project_dir,
                capture_output=True,
                text=True,
                timeout=120
            )
            
            if result.returncode != 0:
                safe_print(f"    [FAIL] PostgreSQL startup failed: {result.stderr}")
                return False
            
            self.running_containers.append(test_project_dir)
            
            # Wait for PostgreSQL to be ready
            safe_print("    [DOCKER] Waiting for PostgreSQL to be ready...")
            time.sleep(15)  # Give PostgreSQL time to initialize
            
            # Test database connectivity and initialization
            test_result = subprocess.run(
                ['docker-compose', 'exec', '-T', 'postgres', 'psql', '-U', 'testuser', '-d', 'testdb', '-c', 'SELECT COUNT(*) FROM test_schema.test_table;'],
                cwd=test_project_dir,
                capture_output=True,
                text=True,
                timeout=30
            )
            
            if test_result.returncode == 0 and "1" in test_result.stdout:
                safe_print("    [PASS] PostgreSQL initialization and data insertion verified")
                return True
            else:
                safe_print("    [WARN] PostgreSQL initialization verification failed")
                return False
            
        except subprocess.TimeoutExpired:
            safe_print("    [FAIL] PostgreSQL test timed out")
            return False
        except Exception as e:
            safe_print(f"    [FAIL] PostgreSQL test failed: {str(e)}")
            return False
    
    def _test_mongodb_comprehensive(self) -> bool:
        """Comprehensive MongoDB testing"""
        try:
            # Create a test project with MongoDB
            test_project_dir = os.path.join(self.temp_dir, "mongo_test")
            os.makedirs(test_project_dir)
            
            # Create docker-compose for MongoDB test
            compose_content = """
version: '3.8'
services:
  mongodb:
    image: mongo:5.0
    environment:
      MONGO_INITDB_ROOT_USERNAME: testuser
      MONGO_INITDB_ROOT_PASSWORD: testpass
      MONGO_INITDB_DATABASE: testdb
    ports:
      - "27017:27017"
    volumes:
      - mongo_data:/data/db
      - ./init-scripts:/docker-entrypoint-initdb.d
    healthcheck:
      test: ["CMD", "mongo", "--eval", "db.adminCommand('ping')"]
      interval: 10s
      timeout: 5s
      retries: 5

volumes:
  mongo_data:
"""
            
            with open(os.path.join(test_project_dir, "docker-compose.yml"), 'w') as f:
                f.write(compose_content)
            
            # Create init scripts directory and script
            init_dir = os.path.join(test_project_dir, "init-scripts")
            os.makedirs(init_dir)
            
            init_script = """
// Test initialization script
db = db.getSiblingDB('testdb');
db.createCollection('test_collection');
db.test_collection.insertOne({
    name: 'test_entry',
    created_at: new Date()
});
"""
            
            with open(os.path.join(init_dir, "01-init.js"), 'w') as f:
                f.write(init_script)
            
            # Start MongoDB container
            safe_print("    [DOCKER] Starting MongoDB container...")
            result = subprocess.run(
                ['docker-compose', 'up', '-d'],
                cwd=test_project_dir,
                capture_output=True,
                text=True,
                timeout=120
            )
            
            if result.returncode != 0:
                safe_print(f"    [FAIL] MongoDB startup failed: {result.stderr}")
                return False
            
            self.running_containers.append(test_project_dir)
            
            # Wait for MongoDB to be ready
            safe_print("    [DOCKER] Waiting for MongoDB to be ready...")
            time.sleep(15)  # Give MongoDB time to initialize
            
            # Test database connectivity and initialization
            test_result = subprocess.run(
                ['docker-compose', 'exec', '-T', 'mongodb', 'mongo', '--eval', 'db.getSiblingDB("testdb").test_collection.count()'],
                cwd=test_project_dir,
                capture_output=True,
                text=True,
                timeout=30
            )
            
            if test_result.returncode == 0 and "1" in test_result.stdout:
                safe_print("    [PASS] MongoDB initialization and data insertion verified")
                return True
            else:
                safe_print("    [WARN] MongoDB initialization verification failed")
                return False
            
        except subprocess.TimeoutExpired:
            safe_print("    [FAIL] MongoDB test timed out")
            return False
        except Exception as e:
            safe_print(f"    [FAIL] MongoDB test failed: {str(e)}")
            return False
    
    def _test_database_init_scripts(self) -> bool:
        """Test database initialization scripts processing"""
        try:
            # Test that init scripts are properly processed in templates
            for user in self.test_users[:1]:  # Test with one user for efficiency
                for project_name, project_dir in [("common", "common")]:
                    if (user, project_name) not in self.test_projects:
                        continue
                    
                    project_path = os.path.join(self.projects_base, user, project_dir)
                    
                    # Check if init scripts directory exists
                    init_scripts_dir = os.path.join(project_path, "init-scripts")
                    if not os.path.exists(init_scripts_dir):
                        safe_print(f"    [WARN] Init scripts directory missing for {user}/{project_name}")
                        continue
                    
                    # Check PostgreSQL init script
                    postgres_init = os.path.join(init_scripts_dir, "postgres", "01-init.sql")
                    if os.path.exists(postgres_init):
                        with open(postgres_init, 'r') as f:
                            content = f.read()
                        
                        # Verify template variables were replaced
                        if "{{" in content:
                            safe_print(f"    [WARN] Unreplaced template variables in PostgreSQL init script")
                        else:
                            safe_print(f"    [PASS] PostgreSQL init script properly processed")
                    
                    # Check MongoDB init script
                    mongo_init = os.path.join(init_scripts_dir, "mongo", "01-init.js")
                    if os.path.exists(mongo_init):
                        with open(mongo_init, 'r') as f:
                            content = f.read()
                        
                        # Verify template variables were replaced
                        if "{{" in content:
                            safe_print(f"    [WARN] Unreplaced template variables in MongoDB init script")
                        else:
                            safe_print(f"    [PASS] MongoDB init script properly processed")
            
            return True
            
        except Exception as e:
            safe_print(f"    [FAIL] Init scripts test failed: {str(e)}")
            return False
    
    def _test_cross_database_connectivity(self) -> bool:
        """Test connectivity between different database services"""
        try:
            # This would test if applications can connect to multiple databases
            # For now, we'll verify that the docker-compose files have proper networking
            
            for user in self.test_users[:1]:  # Test with one user for efficiency
                user_dir = os.path.join(self.projects_base, user)
                
                for project_name in ["common"]:
                    project_path = os.path.join(user_dir, project_name)
                    compose_file = os.path.join(project_path, "docker-compose.yml")
                    
                    if not os.path.exists(compose_file):
                        continue
                    
                    with open(compose_file, 'r') as f:
                        content = f.read()
                    
                    # Check that multiple databases are configured
                    has_postgres = "postgres:" in content
                    has_mongo = "mongodb:" in content
                    has_redis = "redis:" in content
                    
                    if has_postgres and has_mongo and has_redis:
                        safe_print(f"    [PASS] Multi-database configuration verified for {user}/{project_name}")
                    else:
                        safe_print(f"    [WARN] Incomplete database configuration for {user}/{project_name}")
                    
                    # Check network configuration
                    if f"{user}_network" in content:
                        safe_print(f"    [PASS] Network isolation configured for {user}")
                    else:
                        safe_print(f"    [WARN] Network isolation not configured for {user}")
            
            return True
            
        except Exception as e:
            safe_print(f"    [FAIL] Cross-database connectivity test failed: {str(e)}")
            return False
    
    def test_advanced_network_isolation(self) -> bool:
        """Test advanced network isolation between student environments"""
        safe_print("\n[NETWORK] Advanced Network Isolation Test")
        safe_print("="*60)
        
        try:
            results = {"isolation_tests": 0, "isolation_passed": 0}
            
            # Test 1: Port Range Isolation
            safe_print("\n[NETWORK] Testing Port Range Isolation")
            if self._test_port_range_isolation():
                results["isolation_passed"] += 1
                safe_print("  [PASS] Port range isolation verified")
            else:
                safe_print("  [FAIL] Port range isolation failed")
            results["isolation_tests"] += 1
            
            # Test 2: Docker Network Isolation
            safe_print("\n[NETWORK] Testing Docker Network Isolation")
            if self._test_docker_network_isolation():
                results["isolation_passed"] += 1
                safe_print("  [PASS] Docker network isolation verified")
            else:
                safe_print("  [FAIL] Docker network isolation failed")
            results["isolation_tests"] += 1
            
            # Test 3: Volume Isolation
            safe_print("\n[NETWORK] Testing Volume Isolation")
            if self._test_volume_isolation():
                results["isolation_passed"] += 1
                safe_print("  [PASS] Volume isolation verified")
            else:
                safe_print("  [FAIL] Volume isolation failed")
            results["isolation_tests"] += 1
            
            # Test 4: Service Name Isolation
            safe_print("\n[NETWORK] Testing Service Name Isolation")
            if self._test_service_name_isolation():
                results["isolation_passed"] += 1
                safe_print("  [PASS] Service name isolation verified")
            else:
                safe_print("  [FAIL] Service name isolation failed")
            results["isolation_tests"] += 1
            
            success_rate = (results["isolation_passed"] / results["isolation_tests"] * 100) if results["isolation_tests"] > 0 else 0
            
            safe_print(f"\n[STATS] Network Isolation Results:")
            safe_print(f"  Tests Performed: {results['isolation_tests']}")
            safe_print(f"  Tests Passed: {results['isolation_passed']}")
            safe_print(f"  Success Rate: {success_rate:.1f}%")
            
            return success_rate >= 75
            
        except Exception as e:
            safe_print(f"[FAIL] Network isolation test failed: {str(e)}")
            return False
    
    def _test_port_range_isolation(self) -> bool:
        """Test that each user has isolated port ranges"""
        try:
            port_assignments = {}
            
            # Collect all port assignments from docker-compose files
            for user in self.test_users:
                user_dir = os.path.join(self.projects_base, user)
                if not os.path.exists(user_dir):
                    continue
                
                user_ports = set()
                
                for project_dir in os.listdir(user_dir):
                    project_path = os.path.join(user_dir, project_dir)
                    compose_file = os.path.join(project_path, "docker-compose.yml")
                    
                    if not os.path.exists(compose_file):
                        continue
                    
                    with open(compose_file, 'r') as f:
                        content = f.read()
                    
                    # Extract port mappings
                    import re
                    port_matches = re.findall(r'"(\d+):\d+"', content)
                    for port_str in port_matches:
                        user_ports.add(int(port_str))
                
                port_assignments[user] = user_ports
            
            # Check for port conflicts between users
            users = list(port_assignments.keys())
            for i in range(len(users)):
                for j in range(i + 1, len(users)):
                    user1, user2 = users[i], users[j]
                    ports1 = port_assignments[user1]
                    ports2 = port_assignments[user2]
                    
                    conflicts = ports1.intersection(ports2)
                    if conflicts:
                        safe_print(f"    [FAIL] Port conflicts between {user1} and {user2}: {conflicts}")
                        return False
            
            safe_print(f"    [PASS] No port conflicts detected between {len(users)} users")
            return True
            
        except Exception as e:
            safe_print(f"    [ERROR] Port range isolation test failed: {str(e)}")
            return False
    
    def _test_docker_network_isolation(self) -> bool:
        """Test Docker network isolation between users"""
        try:
            # Check that each user has their own network
            networks_found = set()
            
            for user in self.test_users:
                user_dir = os.path.join(self.projects_base, user)
                if not os.path.exists(user_dir):
                    continue
                
                for project_dir in os.listdir(user_dir):
                    project_path = os.path.join(user_dir, project_dir)
                    compose_file = os.path.join(project_path, "docker-compose.yml")
                    
                    if not os.path.exists(compose_file):
                        continue
                    
                    with open(compose_file, 'r') as f:
                        content = f.read()
                    
                    # Check for user-specific network
                    expected_network = f"{user}_network"
                    if expected_network in content:
                        networks_found.add(expected_network)
                    else:
                        safe_print(f"    [WARN] User-specific network not found for {user}")
            
            if len(networks_found) >= len(self.test_users):
                safe_print(f"    [PASS] User-specific networks configured")
                return True
            else:
                safe_print(f"    [WARN] Some users missing network isolation")
                return False
            
        except Exception as e:
            safe_print(f"    [ERROR] Docker network isolation test failed: {str(e)}")
            return False
    
    def _test_volume_isolation(self) -> bool:
        """Test that volumes are isolated between users"""
        try:
            # Check that volume names include user identification
            for user in self.test_users:
                user_dir = os.path.join(self.projects_base, user)
                if not os.path.exists(user_dir):
                    continue
                
                for project_dir in os.listdir(user_dir):
                    project_path = os.path.join(user_dir, project_dir)
                    compose_file = os.path.join(project_path, "docker-compose.yml")
                    
                    if not os.path.exists(compose_file):
                        continue
                    
                    with open(compose_file, 'r') as f:
                        content = f.read()
                    
                    # Check that volumes don't conflict
                    # In our current implementation, volumes are project-scoped
                    # which provides isolation
                    if "volumes:" in content:
                        safe_print(f"    [PASS] Volume configuration found for {user}/{project_dir}")
            
            return True
            
        except Exception as e:
            safe_print(f"    [ERROR] Volume isolation test failed: {str(e)}")
            return False
    
    def _test_service_name_isolation(self) -> bool:
        """Test that service names don't conflict between users"""
        try:
            # Service names are scoped within docker-compose projects
            # so they should be naturally isolated
            service_names = {}
            
            for user in self.test_users:
                user_dir = os.path.join(self.projects_base, user)
                if not os.path.exists(user_dir):
                    continue
                
                user_services = set()
                
                for project_dir in os.listdir(user_dir):
                    project_path = os.path.join(user_dir, project_dir)
                    compose_file = os.path.join(project_path, "docker-compose.yml")
                    
                    if not os.path.exists(compose_file):
                        continue
                    
                    with open(compose_file, 'r') as f:
                        content = f.read()
                    
                    # Extract service names
                    import re
                    service_matches = re.findall(r'^  (\w+):', content, re.MULTILINE)
                    for service in service_matches:
                        if service != "version" and service != "services" and service != "volumes" and service != "networks":
                            user_services.add(f"{project_dir}_{service}")
                
                service_names[user] = user_services
            
            # Check for service name patterns that indicate proper isolation
            total_services = sum(len(services) for services in service_names.values())
            if total_services > 0:
                safe_print(f"    [PASS] Service isolation verified ({total_services} services across {len(service_names)} users)")
                return True
            else:
                safe_print(f"    [WARN] No services found for isolation testing")
                return False
            
        except Exception as e:
            safe_print(f"    [ERROR] Service name isolation test failed: {str(e)}")
            return False
    
    def cleanup_test_environment(self):
        """Clean up the enhanced test environment"""
        safe_print("\n[CLEANUP] Cleaning up enhanced test environment...")
        
        # Stop all running containers
        for container_dir in self.running_containers:
            try:
                subprocess.run(
                    ['docker-compose', 'down', '-v'],
                    cwd=container_dir,
                    capture_output=True,
                    timeout=60
                )
                safe_print(f"  [CLEANUP] Stopped containers in {os.path.basename(container_dir)}")
            except:
                pass
        
        # Remove temporary directory
        if self.temp_dir and os.path.exists(self.temp_dir):
            shutil.rmtree(self.temp_dir)
            safe_print(f"  [CLEANUP] Removed temporary directory")
    
    def run_enhanced_end_to_end_validation(self) -> bool:
        """Run all enhanced end-to-end validation tests"""
        safe_print("Starting Enhanced End-to-End Workflow Validation")
        safe_print("="*70)
        
        start_time = time.time()
        tests_passed = 0
        total_tests = 0
        
        try:
            # Setup multi-user environment
            if not self.setup_multi_user_environment():
                safe_print("[FAIL] Failed to setup multi-user environment")
                return False
            
            # Test 1: Complete Multi-User Workflows
            total_tests += 1
            if self.test_complete_multi_user_workflows():
                tests_passed += 1
            
            # Test 2: Comprehensive Database Initialization
            total_tests += 1
            if self.test_comprehensive_database_initialization():
                tests_passed += 1
            
            # Test 3: Advanced Network Isolation
            total_tests += 1
            if self.test_advanced_network_isolation():
                tests_passed += 1
            
        finally:
            self.cleanup_test_environment()
        
        # Generate comprehensive report
        duration = time.time() - start_time
        success_rate = (tests_passed / total_tests * 100) if total_tests > 0 else 0
        
        safe_print(f"\n{'='*70}")
        safe_print(f"ENHANCED END-TO-END VALIDATION RESULTS")
        safe_print(f"{'='*70}")
        safe_print(f"Total Test Suites: {total_tests}")
        safe_print(f"Passed Test Suites: {tests_passed}")
        safe_print(f"Failed Test Suites: {total_tests - tests_passed}")
        safe_print(f"Success Rate: {success_rate:.1f}%")
        safe_print(f"Duration: {duration:.2f}s")
        safe_print(f"Docker Available: {'Yes' if self.docker_available else 'No'}")
        safe_print(f"Compose Available: {'Yes' if self.compose_available else 'No'}")
        
        # Detailed capabilities tested
        safe_print(f"\n[INFO] Enhanced Capabilities Validated:")
        safe_print(f"  - Multi-user workflow isolation")
        safe_print(f"  - Complete project lifecycle (create, copy, manage)")
        safe_print(f"  - PostgreSQL initialization and connectivity")
        safe_print(f"  - MongoDB initialization and connectivity")
        safe_print(f"  - Database initialization scripts processing")
        safe_print(f"  - Cross-database connectivity configuration")
        safe_print(f"  - Port range isolation between users")
        safe_print(f"  - Docker network isolation")
        safe_print(f"  - Volume and service name isolation")
        safe_print(f"  - Template variable substitution")
        safe_print(f"  - Project directory structure validation")
        
        # Final assessment
        if success_rate >= 90:
            safe_print(f"\n[PASS] EXCELLENT: Enhanced end-to-end validation successful")
            safe_print(f"  System is ready for multi-user production deployment")
        elif success_rate >= 75:
            safe_print(f"\n[PASS] GOOD: Enhanced validation mostly successful")
            safe_print(f"  System is functional with minor issues to address")
        elif success_rate >= 50:
            safe_print(f"\n[WARN] FAIR: Enhanced validation has significant issues")
            safe_print(f"  Address failing tests before production deployment")
        else:
            safe_print(f"\n[FAIL] POOR: Enhanced validation failed")
            safe_print(f"  Major issues require immediate attention")
        
        # Recommendations
        safe_print(f"\n[TIP] Recommendations:")
        if not self.docker_available:
            safe_print(f"  - Install Docker to enable full container testing")
        if not self.compose_available:
            safe_print(f"  - Install Docker Compose for orchestration testing")
        if success_rate < 100:
            safe_print(f"  - Review failed test suites and address issues")
        safe_print(f"  - Test with actual multi-user concurrent usage")
        safe_print(f"  - Validate with production-like resource constraints")
        safe_print(f"  - Consider load testing with multiple simultaneous users")
        
        return success_rate >= 75


def main():
    """Main entry point for enhanced end-to-end validation"""
    validator = EnhancedEndToEndValidator()
    
    try:
        success = validator.run_enhanced_end_to_end_validation()
        return 0 if success else 1
    except KeyboardInterrupt:
        safe_print("\n[INFO] Enhanced validation interrupted by user")
        return 1
    except Exception as e:
        safe_print(f"\n[FAIL] Enhanced validation failed: {str(e)}")
        return 1
    finally:
        try:
            validator.cleanup_test_environment()
        except:
            pass


if __name__ == "__main__":
    sys.exit(main())